# -*- coding: utf-8 -*-
"""Federated Training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tE-M1T-9BL-HglL5A7asx4b31Sdyhcdq
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import numpy as np
import random
import os
import matplotlib.pyplot as plt

# 定义 MLP 模型
class MLPModel(nn.Module):
    def __init__(self):
        super(MLPModel, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 200)  # 第一层，输入维度 784 -> 200
        self.fc2 = nn.Linear(200, 200)      # 第二层，200 -> 200
        self.fc3 = nn.Linear(200, 10)       # 输出层，200 -> 10
        self.relu = nn.ReLU()

    def forward(self, x):
        x = x.view(x.size(0), -1)  # 展平输入 (batch_size, 1, 28, 28) -> (batch_size, 784)
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)  # 直接输出，不使用 Softmax（因为 PyTorch 的 CrossEntropyLoss 里已经包含了）
        return x

# 加载 MNIST 数据集
def load_mnist_data(data_path="./data"):
    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])

    if os.path.exists(os.path.join(data_path, "MNIST/raw/train-images-idx3-ubyte")):
        print("✅ MNIST 数据集已存在，跳过下载。")
    else:
        print("⬇️ 正在下载 MNIST 数据集...")

    train_data = datasets.MNIST(root=data_path, train=True, transform=transform, download=True)
    test_data = datasets.MNIST(root=data_path, train=False, transform=transform, download=True)

    visualize_mnist_samples(train_data)
    return train_data, test_data

# 显示数据集示例图片
def visualize_mnist_samples(dataset, num_samples=10):
    fig, axes = plt.subplots(1, num_samples, figsize=(num_samples * 1.2, 1.5))
    for i in range(num_samples):
        img, label = dataset[i]
        axes[i].imshow(img.squeeze(), cmap="gray")
        axes[i].set_title(label)
        axes[i].axis("off")
    plt.show()

# 分割 MNIST 数据，使每个客户端只包含某个数字类别
def split_data_by_label(dataset):
    # 自定义每个类别的数据量
    client_data_sizes = {
        0: 5000,
        1: 7000,
        2: 6000,
        3: 8000,
        4: 4000,
        5: 9000,
        6: 3000,
        7: 10000,
        8: 7500,
        9: 6500
    }

    label_to_indices = {i: [] for i in range(10)}  # 记录每个类别的索引

    # 收集每个类别的数据索引
    for idx, (_, label) in enumerate(dataset):
        label_to_indices[label].append(idx)

    # 为每个 client 选择对应类别的数据，并裁剪成需要的数量
    client_datasets = []
    for label, size in client_data_sizes.items():
        indices = label_to_indices[label][:size]  # 取前 size 个样本
        client_datasets.append((label, torch.utils.data.Subset(dataset, indices)))  # 存储 (类别, 数据集)

    print("📊 客户端数据分布:", client_data_sizes)
    return client_datasets, client_data_sizes

# 本地训练函数
def local_train(model, train_loader, epochs=5, lr=0.01):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=lr)
    model.train()
    for epoch in range(epochs):
        for batch_x, batch_y in train_loader:
            optimizer.zero_grad()
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
    return model.state_dict()

# 联邦平均聚合函数
def fed_avg(global_model, client_state_dicts, client_sizes):
    global_dict = global_model.state_dict()
    total_data = sum(client_sizes.values())  # 计算所有客户端数据总量
    for key in global_dict.keys():
        global_dict[key] = sum(client_state[key] * (client_sizes[label] / total_data)
                               for (label, client_state) in client_state_dicts)
    global_model.load_state_dict(global_dict)
    return global_model

# 评估模型
def evaluate(model, test_loader):
    model.eval()
    criterion = nn.CrossEntropyLoss()
    correct, total, total_loss = 0, 0, 0.0
    with torch.no_grad():
        for batch_x, batch_y in test_loader:
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            total_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += batch_y.size(0)
            correct += (predicted == batch_y).sum().item()
    accuracy = correct / total * 100
    return total_loss / len(test_loader), accuracy

def main():
    torch.manual_seed(0)
    random.seed(0)
    np.random.seed(0)

    # 加载 MNIST 数据集
    train_data, test_data = load_mnist_data()

    # 生成客户端数据集，每个客户端只包含特定类别
    client_datasets, client_data_sizes = split_data_by_label(train_data)

    # 创建数据加载器
    client_loaders = {label: data.DataLoader(dataset, batch_size=32, shuffle=True)
                      for label, dataset in client_datasets}
    test_loader = data.DataLoader(test_data, batch_size=32, shuffle=False)

    # 初始化全局模型
    global_model = MLPModel()

    rounds = 10  # 联邦学习轮数
    for r in range(rounds):
        print(f"\n🔄 第 {r+1} 轮聚合")
        client_state_dicts = []

        # 客户端本地训练
        for label, client_loader in client_loaders.items():
            local_model = MLPModel()
            local_model.load_state_dict(global_model.state_dict())  # 复制全局模型参数
            local_state = local_train(local_model, client_loader, epochs=1, lr=0.01)  # 训练 1 轮
            client_state_dicts.append((label, local_state))  # 存储 (类别, 训练后的参数)

            param_mean = {name: param.mean().item() for name, param in local_model.named_parameters()}
            print(f"  ✅ 客户端 {label} (类别 {label}) 训练完成 | 样本数量: {client_data_sizes[label]}")
            print(f"    📌 客户端 {label} 模型参数均值: {param_mean}")

        # 聚合模型参数
        global_model = fed_avg(global_model, client_state_dicts, client_data_sizes)

        # 计算全局模型参数平均值
        global_param_mean = {name: param.mean().item() for name, param in global_model.named_parameters()}
        print(f"🔄 轮 {r+1} 结束后，全局模型参数均值: {global_param_mean}")

        # 评估模型
        loss, accuracy = evaluate(global_model, test_loader)
        print(f"📊 测试集损失: {loss:.4f} | 测试集准确率: {accuracy:.2f}%")

    # 输出最终模型的性能
    final_loss, final_accuracy = evaluate(global_model, test_loader)
    print(f"\n🎯 Loss of final model test dataset: {final_loss:.4f}")
    print(f"🎯 Final model test set accuracy: {final_accuracy:.2f}%")

if __name__ == "__main__":
    main()